{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3362,"databundleVersionId":31148,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kedi ve KÃ¶pek SÄ±nÄ±flandÄ±rmasÄ± CNN Projesi â€“ VGG16 Transfer Ã–ÄŸrenimi + Grad-CAM + Random Search + L2 DÃ¼zenleme\n## 1. Ã‡alÄ±ÅŸma OrtamÄ±nÄ±n HazÄ±rlanmasÄ±\n\nBu kÄ±sÄ±mda, proje sÃ¼resince kullanacaÄŸÄ±mÄ±z tÃ¼m kÃ¼tÃ¼phaneler yÃ¼klenerek Ã§alÄ±ÅŸma ortamÄ± hazÄ±rlanÄ±r. AmaÃ§, veri iÅŸleme, gÃ¶rselleÅŸtirme, model oluÅŸturma ve performans deÄŸerlendirmesi iÃ§in gerekli araÃ§larÄ± hazÄ±r hale getirmektir.\n\n---\n\n### ğŸ”¹ Temel KÃ¼tÃ¼phaneler\n- **NumPy (`np`)** â†’ SayÄ±sal hesaplamalar, dizi ve matris iÅŸlemleri iÃ§in.  \n- **Matplotlib & Seaborn** â†’ EÄŸitim sÄ±rasÄ±nda doÄŸruluk ve kayÄ±p grafikleri ile Confusion Matrix gÃ¶rselleÅŸtirmeleri.  \n- **os & zipfile** â†’ Dosya ve klasÃ¶r yÃ¶netimi, sÄ±kÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ dosyalarÄ±n aÃ§Ä±lmasÄ±.  \n- **cv2 (OpenCV)** â†’ GÃ¶rsellerin okunmasÄ±, yeniden boyutlandÄ±rÄ±lmasÄ± ve Ã¶n iÅŸleme.  \n- **tqdm** â†’ DÃ¶ngÃ¼lerde ilerleme durumunu gÃ¶stermek iÃ§in.  \n- **random** â†’ Rastgele seÃ§imler, Ã¶rneÄŸin rastgele gÃ¶rsel gÃ¶stermek iÃ§in.  \n- **warnings.filterwarnings('ignore')** â†’ Gereksiz uyarÄ±larÄ± gizleyerek temiz bir Ã§Ä±ktÄ± saÄŸlar.\n\n---\n\n### ğŸ”¹ Scikit-learn AraÃ§larÄ±\n- **train_test_split** â†’ Veri setini eÄŸitim, doÄŸrulama ve test kÃ¼melerine bÃ¶ler.  \n- **classification_report & confusion_matrix** â†’ Modelin performansÄ±nÄ± Ã¶lÃ§mek iÃ§in detaylÄ± metrikler sunar.\n\n---\n\n### ğŸ”¹ TensorFlow / Keras BileÅŸenleri\n- **Model, Layers (Input, Dense, Flatten, Dropout)** â†’ CNN yapÄ±sÄ±nÄ± kurmak iÃ§in gerekli katmanlar.  \n- **ImageDataGenerator** â†’ Veri artÄ±rma teknikleri (dÃ¶ndÃ¼rme, yakÄ±nlaÅŸtÄ±rma, yatay/vertical Ã§evirme).  \n- **to_categorical** â†’ Etiketleri one-hot formatÄ±na Ã§evirir.  \n- **Callbacks**:\n  - `EarlyStopping`: Overfitting Ã¶nlemek iÃ§in eÄŸitimi durdurur.  \n  - `ModelCheckpoint`: En iyi model aÄŸÄ± kaydeder.  \n  - `ReduceLROnPlateau`: Ã–ÄŸrenme oranÄ±nÄ± otomatik olarak ayarlar.  \n- **VGG16 & preprocess_input** â†’ Ã–nceden eÄŸitilmiÅŸ model ve uygun giriÅŸ verisi Ã¶n iÅŸleme.  \n- **l2** â†’ AÄŸÄ±rlÄ±klara ceza ekleyerek aÅŸÄ±rÄ± uyumu (overfitting) azaltÄ±r.\n\n---\n\n### ğŸ”¹ TensorFlow SÃ¼rÃ¼mÃ¼ KontrolÃ¼\nOrtamda yÃ¼klÃ¼ TensorFlow sÃ¼rÃ¼mÃ¼nÃ¼ gÃ¶rÃ¼ntÃ¼lemek iÃ§in:\n```python\nprint(\"TensorFlow sÃ¼rÃ¼mÃ¼:\", tf.__version__)\n","metadata":{}},{"cell_type":"code","source":"# 1. Ortam Kurulumu\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\nimport zipfile\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.regularizers import l2\n\nprint(\"TensorFlow version:\", tf.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T00:14:59.702951Z","iopub.execute_input":"2025-09-25T00:14:59.703130Z","iopub.status.idle":"2025-09-25T00:15:15.460764Z","shell.execute_reply.started":"2025-09-25T00:14:59.703113Z","shell.execute_reply":"2025-09-25T00:15:15.459903Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Veri YÃ¼kleme ve EÄŸitim-DoÄŸrulama-Test BÃ¶lÃ¼nmesi\n\nBu bÃ¶lÃ¼mde, Dogs vs Cats veri seti aÃ§Ä±lÄ±r, gÃ¶rseller iÅŸlenir, etiketlenir ve eÄŸitim sÃ¼reci iÃ§in **eÄŸitim, doÄŸrulama ve test** kÃ¼melerine ayrÄ±lÄ±r.\n\n---\n\n### ğŸ”¹ Veri Setini AÃ§ma\n- Kaggle ortamÄ±ndaki `train.zip` dosyasÄ± `/kaggle/working/` dizinine Ã§Ä±karÄ±lÄ±r.  \n- Ã‡Ä±karÄ±lan dosyalarÄ±n yolu `rec_egitim_yolu` deÄŸiÅŸkeninde saklanÄ±r.\n\n---\n\n### ğŸ”¹ Veri YÃ¼kleme Fonksiyonu\n- `veri_yukle` fonksiyonu ÅŸu iÅŸlemleri yapar:  \n  - KÃ¶pek gÃ¶rselleri â†’ etiket **1**  \n  - Kedi gÃ¶rselleri â†’ etiket **0**  \n- Her bir gÃ¶rsel:  \n  - `cv2.imread` ile okunur  \n  - `(128,128)` boyutuna yeniden boyutlandÄ±rÄ±lÄ±r  \n  - `preprocess_input` ile normalize edilir  \n- Fonksiyonun Ã§Ä±ktÄ±larÄ±:  \n  - `X` â†’ GÃ¶rsellerin NumPy dizisi  \n  - `y` â†’ Etiketler\n\n---\n\n### ğŸ”¹ One-Hot Encoding\n- `to_categorical` kullanÄ±larak etiketler `[0,1]` veya `[1,0]` formatÄ±na Ã§evrilir.  \n- Bu dÃ¶nÃ¼ÅŸÃ¼m, `categorical_crossentropy` kayÄ±p fonksiyonu ile uyumlu Ã§alÄ±ÅŸÄ±r.\n\n---\n\n### ğŸ”¹ SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± KontrolÃ¼\n- `sns.barplot` ile kedi ve kÃ¶pek gÃ¶rsellerinin sayÄ±sÄ± gÃ¶rselleÅŸtirilir.  \n- Bu adÄ±m, veri setinde sÄ±nÄ±f dengesinin korunup korunmadÄ±ÄŸÄ±nÄ± kontrol etmek iÃ§in Ã¶nemlidir.\n\n---\n\n### ğŸ”¹ Ã–rnek GÃ¶rsellerin GÃ¶sterimi\n- Rastgele seÃ§ilen bir kedi ve bir kÃ¶pek gÃ¶rseli ekrana basÄ±lÄ±r.  \n- BÃ¶ylece veri yÃ¼kleme ve Ã¶n iÅŸleme sÃ¼recinin doÄŸru Ã§alÄ±ÅŸtÄ±ÄŸÄ± doÄŸrulanÄ±r.\n\n---\n\n### ğŸ”¹ EÄŸitim-DoÄŸrulama-Test AyrÄ±mÄ±\n- `train_test_split` ile veri Ã¶nce **%80 eÄŸitim / %20 test** olacak ÅŸekilde bÃ¶lÃ¼nÃ¼r.  \n- EÄŸitim verisinin **%20â€™si** ayrÄ±ca doÄŸrulama kÃ¼mesi olarak ayrÄ±lÄ±r.  \n- `stratify` parametresi sayesinde kedi ve kÃ¶pek oranÄ± tÃ¼m alt kÃ¼melerde korunur.  \n- SonuÃ§ olarak Ã¼Ã§ alt kÃ¼me oluÅŸur:  \n  - **EÄŸitim (Train)** â†’ Modelin Ã¶ÄŸrenmesi iÃ§in  \n  - **DoÄŸrulama (Validation)** â†’ Hiperparametre ayarlamalarÄ± ve overfitting kontrolÃ¼ iÃ§in  \n  - **Test (Test)** â†’ Nihai model deÄŸerlendirmesi iÃ§in\n\n---\n\nâœ… **Ã–zet:**  \nBu aÅŸamada veri seti baÅŸarÄ±yla yÃ¼klenmiÅŸ, iÅŸlenmiÅŸ, sÄ±nÄ±f daÄŸÄ±lÄ±mÄ± kontrol edilmiÅŸ ve gÃ¶rseller **eÄŸitim, doÄŸrulama ve test** kÃ¼meleri halinde model eÄŸitimi iÃ§in hazÄ±r hÃ¢le getirilmiÅŸtir.\n","metadata":{}},{"cell_type":"code","source":"# 2. Veri YÃ¼kleme ve Train-Validation-Test Split\nort_veri_yolu = \"/kaggle/input/dogs-vs-cats\"\nwith zipfile.ZipFile(os.path.join(ort_veri_yolu, \"train.zip\"), 'r') as zip_ref:\n    zip_ref.extractall(\"/kaggle/working/\")\nrec_egitim_yolu = \"/kaggle/working/train\"\n\ndef veri_yukle(veri_yolu, boyut=(128,128)):\n    goruntuler, etiketler = [], []\n    kopek_yollari = [os.path.join(veri_yolu,f) for f in os.listdir(veri_yolu) if f.startswith('dog')]\n    for yol in tqdm(kopek_yollari, desc=\"KÃ¶pekler\"):\n        img = cv2.imread(yol)\n        if img is not None:\n            img = cv2.resize(img, boyut)\n            img = preprocess_input(img)\n            goruntuler.append(img)\n            etiketler.append(1)\n    kedi_yollari = [os.path.join(veri_yolu,f) for f in os.listdir(veri_yolu) if f.startswith('cat')]\n    for yol in tqdm(kedi_yollari, desc=\"Kediler\"):\n        img = cv2.imread(yol)\n        if img is not None:\n            img = cv2.resize(img, boyut)\n            img = preprocess_input(img)\n            goruntuler.append(img)\n            etiketler.append(0)\n    return np.array(goruntuler), np.array(etiketler)\n\nX, y = veri_yukle(rec_egitim_yolu)\ny_cat = to_categorical(y, 2)\n\n# SÄ±nÄ±f daÄŸÄ±lÄ±mÄ± gÃ¶rselleÅŸtirme\nunique, counts = np.unique(y, return_counts=True)\nplt.figure(figsize=(6,4))\nsns.barplot(x=['Kedi','KÃ¶pek'], y=counts)\nplt.title(\"SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±\")\nplt.ylabel(\"GÃ¶rÃ¼ntÃ¼ SayÄ±sÄ±\")\nplt.show()\n\n# Ã–rnek gÃ¶rseller\nplt.figure(figsize=(12,6))\nfor i, label in enumerate([0,1]):  # 0=Kedi, 1=KÃ¶pek\n    idx = np.where(y==label)[0]\n    sample_idx = random.choice(idx)\n    img = ((X[sample_idx]+1)*127.5).astype('uint8')\n    plt.subplot(1,2,i+1)\n    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title('Kedi' if label==0 else 'KÃ¶pek')\nplt.show()\n\n# Train-Test-Validation split\nX_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.2, stratify=y, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.2, stratify=np.argmax(y_train, axis=1), random_state=42\n)\nprint(f\"Train: {X_train.shape}, Validation: {X_val.shape}, Test: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T00:15:15.462257Z","iopub.execute_input":"2025-09-25T00:15:15.462793Z","iopub.status.idle":"2025-09-25T00:15:55.699975Z","shell.execute_reply.started":"2025-09-25T00:15:15.462774Z","shell.execute_reply":"2025-09-25T00:15:55.699223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Veri ArtÄ±rma (Data Augmentation)\n\nBu bÃ¶lÃ¼mde, eÄŸitim verisinin Ã§eÅŸitliliÄŸini artÄ±rmak ve modelin **overfitting** yapmasÄ±nÄ± engellemek iÃ§in **veri artÄ±rma teknikleri** uygulanÄ±r.\n\n---\n\n### ğŸ”¹ Veri ArtÄ±rmanÄ±n AmaÃ§larÄ±\n- EÄŸitim sÄ±rasÄ±nda verilerden farklÄ± varyasyonlar oluÅŸturur.  \n- Modelin genelleme yeteneÄŸini gÃ¼Ã§lendirir.  \n- Ã–zellikle kÃ¼Ã§Ã¼k veri setlerinde baÅŸarÄ±yÄ± artÄ±rÄ±r.\n\n---\n\n### ğŸ”¹ KullanÄ±lan Parametreler\n- **rotation_range=40** â†’ GÃ¶rselleri Â±40 derece arasÄ±nda rastgele dÃ¶ndÃ¼rÃ¼r.  \n- **width_shift_range=0.3** â†’ GÃ¶rselleri yatay eksende %30â€™a kadar kaydÄ±rÄ±r.  \n- **height_shift_range=0.3** â†’ GÃ¶rselleri dikey eksende %30â€™a kadar kaydÄ±rÄ±r.  \n- **horizontal_flip=True** â†’ GÃ¶rselleri yatayda Ã§evirir (ayna etkisi).  \n- **zoom_range=0.3** â†’ GÃ¶rselleri %30 oranÄ±nda yakÄ±nlaÅŸtÄ±rÄ±r veya uzaklaÅŸtÄ±rÄ±r.  \n- **brightness_range=[0.7,1.3]** â†’ GÃ¶rsellerin parlaklÄ±ÄŸÄ±nÄ± %70â€“%130 aralÄ±ÄŸÄ±nda deÄŸiÅŸtirir.\n\n---\n\nâœ… **Ã–zet:**  \nBu aÅŸamada `ImageDataGenerator` ile veriler Ã¼zerinde dÃ¶ndÃ¼rme, kaydÄ±rma, yakÄ±nlaÅŸtÄ±rma, yatay Ã§evirme ve parlaklÄ±k ayarlamalarÄ± uygulanÄ±r. BÃ¶ylece model, farklÄ± gÃ¶rsel varyasyonlarÄ±yla eÄŸitilir ve daha gÃ¼Ã§lÃ¼ bir genelleme yeteneÄŸi kazanÄ±r.\n","metadata":{}},{"cell_type":"code","source":"# 3. Data Augmentation\ndatagen = ImageDataGenerator(\n    rotation_range=40,\n    width_shift_range=0.3,\n    height_shift_range=0.3,\n    horizontal_flip=True,\n    zoom_range=0.3,\n    brightness_range=[0.7,1.3]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T00:15:55.700806Z","iopub.execute_input":"2025-09-25T00:15:55.701088Z","iopub.status.idle":"2025-09-25T00:15:55.705002Z","shell.execute_reply.started":"2025-09-25T00:15:55.701061Z","shell.execute_reply":"2025-09-25T00:15:55.704363Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Random Search ile Hiperparametre Denemeleri\n\nBu bÃ¶lÃ¼mde, farklÄ± **hiperparametre kombinasyonlarÄ±** test edilerek modelin en iyi performansÄ± elde etmesi hedeflenir. YaklaÅŸÄ±m, **Random Search** mantÄ±ÄŸÄ±na dayanmaktadÄ±r.\n\n---\n\n### ğŸ”¹ AmaÃ§\n- Ã–ÄŸrenme oranÄ± (learning rate), dropout oranÄ± ve batch size gibi hiperparametrelerin farklÄ± deÄŸerlerini deneyerek modelin performansÄ±nÄ± deÄŸerlendirmek.  \n- Validation (doÄŸrulama) baÅŸarÄ±sÄ±nÄ± en yÃ¼ksek seviyeye Ã§Ä±karan parametre setini belirlemek.\n\n---\n\n### ğŸ”¹ Ä°ÅŸlem AdÄ±mlarÄ±\n\n1. **Parametre KombinasyonlarÄ±**\n   - ÃœÃ§ farklÄ± set oluÅŸturulmuÅŸtur:  \n     - `{learning_rate: 0.001, dropout_rate: 0.5, batch_size: 32}`  \n     - `{learning_rate: 0.0005, dropout_rate: 0.5, batch_size: 32}`  \n     - `{learning_rate: 0.0001, dropout_rate: 0.4, batch_size: 64}`\n\n2. **Model Kurulumu (VGG16 Transfer Learning)**\n   - `VGG16` tabanlÄ± Ã¶nceden eÄŸitilmiÅŸ model (`imagenet`) kullanÄ±lÄ±r.  \n   - `include_top=False` â†’ Son sÄ±nÄ±flandÄ±rma katmanÄ± Ã§Ä±karÄ±lÄ±r.  \n   - TÃ¼m katmanlar **dondurulur** (`trainable=False`) ve Ã¶zellik Ã§Ä±karÄ±cÄ± olarak kullanÄ±lÄ±r.\n\n3. **Yeni KatmanlarÄ±n Eklenmesi**\n   - `Flatten` â†’ Ã–zellikleri tek boyuta indirger.  \n   - `Dense(512, relu)` â†’ 512 nÃ¶ronlu tam baÄŸlÄ± katman + **L2 regularization**.  \n   - `Dropout` â†’ Parametre setindeki deÄŸere gÃ¶re uygulanÄ±r.  \n   - `Dense(2, softmax)` â†’ Ã‡Ä±kÄ±ÅŸ katmanÄ± (kedi ve kÃ¶pek sÄ±nÄ±flarÄ±).\n\n4. **Modelin Derlenmesi**\n   - Optimizasyon: **Adam**  \n   - Learning rate parametre setinden alÄ±nÄ±r  \n   - KayÄ±p fonksiyonu: **categorical_crossentropy**  \n   - Ã–lÃ§Ã¼t: **accuracy**\n\n5. **EÄŸitim SÃ¼reci**\n   - `ImageDataGenerator` ile artÄ±rÄ±lmÄ±ÅŸ eÄŸitim verisi kullanÄ±lÄ±r.  \n   - `batch_size` parametre setinden alÄ±nÄ±r.  \n   - 5 epoch boyunca eÄŸitim yapÄ±lÄ±r.  \n   - Validation seti ile doÄŸruluk takip edilir.\n\n6. **SonuÃ§larÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±**\n   - Her denemenin en iyi **validation accuracy** kaydedilir.  \n   - En yÃ¼ksek doÄŸruluk saÄŸlayan parametre seti `best_params` olarak seÃ§ilir.\n\n---\n\nâœ… **Ã–zet:**  \nBu adÄ±mda farklÄ± **learning rate, dropout ve batch size** kombinasyonlarÄ± test edilerek, modelin doÄŸrulama baÅŸarÄ±sÄ±nÄ± en Ã¼st dÃ¼zeye Ã§Ä±karan parametreler belirlenmiÅŸtir. Bu yÃ¶ntem, **hiperparametre optimizasyonu** ile model performansÄ±nÄ± artÄ±rmayÄ± saÄŸlar.\n","metadata":{}},{"cell_type":"code","source":"# 4. Random Search Hiperparametre Denemeleri\nparam_combinations = [\n    {'learning_rate':0.001,'dropout_rate':0.5,'batch_size':32},\n    {'learning_rate':0.0005,'dropout_rate':0.5,'batch_size':32},\n    {'learning_rate':0.0001,'dropout_rate':0.4,'batch_size':64},\n]\n\nbest_score = 0\nbest_params = None\n\nfor i, params in enumerate(param_combinations):\n    print(f\"\\nTest Kombinasyonu {i+1}/{len(param_combinations)}: {params}\")\n    \n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128,128,3))\n    for layer in base_model.layers:\n        layer.trainable = False\n    \n    x = Flatten()(base_model.output)\n    x = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\n    x = Dropout(params['dropout_rate'])(x)\n    outputs = Dense(2, activation='softmax')(x)\n    \n    model = Model(base_model.input, outputs)\n    opt = tf.keras.optimizers.Adam(learning_rate=params['learning_rate'])\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    history = model.fit(\n        datagen.flow(X_train, y_train, batch_size=params['batch_size']),\n        steps_per_epoch=len(X_train)//params['batch_size'],\n        epochs=5,\n        validation_data=(X_val, y_val),\n        verbose=1\n    )\n    \n    val_acc = max(history.history['val_accuracy'])\n    print(f\"En iyi validation accuracy: {val_acc:.4f}\")\n    \n    if val_acc > best_score:\n        best_score = val_acc\n        best_params = params\n\nprint(f\"\\nEn iyi parametreler: {best_params}, Validation Accuracy: {best_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T00:15:55.705785Z","iopub.execute_input":"2025-09-25T00:15:55.706037Z","iopub.status.idle":"2025-09-25T00:34:09.560241Z","shell.execute_reply.started":"2025-09-25T00:15:55.706012Z","shell.execute_reply":"2025-09-25T00:34:09.559681Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Nihai Model EÄŸitimi\n\nBu bÃ¶lÃ¼mde, **en iyi hiperparametreler** kullanÄ±larak modelin son eÄŸitimi gerÃ§ekleÅŸtirilir. EÄŸitim sÄ±rasÄ±nda **callbacks** ile overfitting Ã¶nlenir ve en iyi aÄŸÄ±rlÄ±klar saklanÄ±r.\n\n---\n\n### ğŸ”¹ Model Kurulumu\n- `VGG16` tabanlÄ± transfer Ã¶ÄŸrenimi modeli kullanÄ±lÄ±r.  \n- `weights='imagenet'` â†’ Ã–nceden eÄŸitilmiÅŸ aÄŸÄ±rlÄ±klar yÃ¼klenir.  \n- `include_top=False` â†’ Son sÄ±nÄ±flandÄ±rma katmanÄ± Ã§Ä±karÄ±lÄ±r.  \n- Katmanlar **dondurulur** (`trainable=False`) â†’ Ã–nceden Ã¶ÄŸrenilmiÅŸ Ã¶zellikler korunur.\n\n---\n\n### ğŸ”¹ Yeni KatmanlarÄ±n Eklenmesi\n- `Flatten` â†’ Ã–zellikleri tek boyutlu hÃ¢le getirir.  \n- `Dense(512, relu)` â†’ 512 nÃ¶ronlu tam baÄŸlÄ± katman + **L2 regularization**.  \n- `Dropout` â†’ Hiperparametre optimizasyonunda belirlenen oran uygulanÄ±r.  \n- `Dense(2, softmax)` â†’ Ã‡Ä±kÄ±ÅŸ katmanÄ± (kedi ve kÃ¶pek sÄ±nÄ±flarÄ±).\n\n---\n\n### ğŸ”¹ Modelin Derlenmesi\n- Optimizasyon: **Adam** ve **en uygun learning rate** kullanÄ±lÄ±r.  \n- KayÄ±p fonksiyonu: **categorical_crossentropy**  \n- Ã–lÃ§Ã¼t: **accuracy**\n\n---\n\n### ğŸ”¹ Callbacks KullanÄ±mÄ±\n- `EarlyStopping` â†’ Validation kaybÄ± 7 epoch boyunca iyileÅŸmezse eÄŸitimi durdurur ve en iyi aÄŸÄ±rlÄ±klarÄ± geri yÃ¼kler.  \n- `ModelCheckpoint` â†’ En iyi aÄŸÄ±rlÄ±klarÄ± `best_model.h5` dosyasÄ±na kaydeder.  \n- `ReduceLROnPlateau` â†’ Validation kaybÄ± 3 epoch boyunca iyileÅŸmezse Ã¶ÄŸrenme oranÄ±nÄ± 0.2 faktÃ¶rÃ¼ ile azaltÄ±r.\n\n---\n\n### ğŸ”¹ Model EÄŸitimi\n- EÄŸitim, `ImageDataGenerator` ile artÄ±rÄ±lmÄ±ÅŸ veriler Ã¼zerinde yapÄ±lÄ±r.  \n- `batch_size` ve diÄŸer hiperparametreler **en iyi parametreler** setinden alÄ±nÄ±r.  \n- 25 epoch boyunca eÄŸitim gerÃ§ekleÅŸtirilir ve validation seti ile performans izlenir.\n\n---\n\nâœ… **Ã–zet:**  \nBu aÅŸamada, transfer Ã¶ÄŸrenimli CNN modeli **en iyi hiperparametreler** ile eÄŸitilmiÅŸ, overfitting kontrol edilmiÅŸtir ve en iyi aÄŸÄ±rlÄ±klar kaydedilmiÅŸtir. Model artÄ±k **test ve deÄŸerlendirme** aÅŸamasÄ±na hazÄ±rdÄ±r.\n","metadata":{}},{"cell_type":"code","source":"# 5. Final Model EÄŸitimi\nfinal_base = VGG16(weights='imagenet', include_top=False, input_shape=(128,128,3))\nfor layer in final_base.layers:\n    layer.trainable = False\n\nx = Flatten()(final_base.output)\nx = Dense(512, activation='relu', kernel_regularizer=l2(0.001))(x)\nx = Dropout(best_params['dropout_rate'])(x)\noutputs = Dense(2, activation='softmax')(x)\nfinal_model = Model(final_base.input, outputs)\n\nfinal_model.compile(\n    optimizer=tf.keras.optimizers.Adam(best_params['learning_rate']),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\ncallbacks = [\n    EarlyStopping(patience=7, restore_best_weights=True),\n    ModelCheckpoint('best_model.h5', save_best_only=True),\n    ReduceLROnPlateau(patience=3, factor=0.2)\n]\n\nhistory = final_model.fit(\n    datagen.flow(X_train, y_train, batch_size=best_params['batch_size']),\n    steps_per_epoch=len(X_train)//best_params['batch_size'],\n    epochs=25,\n    validation_data=(X_val, y_val),\n    callbacks=callbacks,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T00:34:09.561678Z","iopub.execute_input":"2025-09-25T00:34:09.561893Z","iopub.status.idle":"2025-09-25T01:04:11.615877Z","shell.execute_reply.started":"2025-09-25T00:34:09.561875Z","shell.execute_reply":"2025-09-25T01:04:11.615263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Model DeÄŸerlendirme ve Overfitting/Underfitting Analizi\n\nBu bÃ¶lÃ¼mde, eÄŸitilen modelin performansÄ± gÃ¶rselleÅŸtirilir, overfitting veya underfitting olup olmadÄ±ÄŸÄ± incelenir ve test verisi Ã¼zerinden deÄŸerlendirme yapÄ±lÄ±r.\n\n---\n\n### ğŸ”¹ EÄŸitim ve DoÄŸrulama Grafikleri\n- `history.history` kullanÄ±larak:  \n  - **Loss** (EÄŸitim ve Validation) grafiÄŸi Ã§izilir  \n  - **Accuracy** (EÄŸitim ve Validation) grafiÄŸi Ã§izilir  \n- Bu grafikler, modelin Ã¶ÄŸrenme sÃ¼recini ve performans eÄŸilimlerini gÃ¶rselleÅŸtirir.\n\n---\n\n### ğŸ”¹ Overfitting / Underfitting KontrolÃ¼\n- EÄŸitim ve doÄŸrulama accuracy farkÄ± hesaplanÄ±r:  \n  ```python\n  acc_diff = abs(val_acc - train_acc)\n\n---\n\n### ğŸ”¹ Durum DeÄŸerlendirmesi\n\n- `acc_diff < 0.05` â†’ âœ… Model dengeli, eÄŸitim ve doÄŸrulama performansÄ± birbirine yakÄ±n.  \n- `val_acc < train_acc` â†’ âš ï¸ Bir miktar overfitting olabilir.  \n- `val_acc > train_acc` â†’ âš ï¸ Bir miktar underfitting olabilir.\n\n---\n\n### ğŸ”¹ Test Verisi Ãœzerinde Performans\n\n- `final_model.evaluate` ile test kaybÄ± ve doÄŸruluk Ã¶lÃ§Ã¼lÃ¼r.  \n- `final_model.predict` ile tahminler alÄ±nÄ±r ve gerÃ§ek sÄ±nÄ±flarla karÅŸÄ±laÅŸtÄ±rÄ±lÄ±r.\n\n---\n\n### ğŸ”¹ Confusion Matrix ve SÄ±nÄ±f BazlÄ± Raporlama\n\n- `confusion_matrix` kullanÄ±larak doÄŸru ve yanlÄ±ÅŸ sÄ±nÄ±flandÄ±rmalar **heatmap** ile gÃ¶rselleÅŸtirilir.  \n- `classification_report` ile her sÄ±nÄ±f iÃ§in:  \n  - Precision  \n  - Recall  \n  - F1-score  \n  raporlanÄ±r (Kedi ve KÃ¶pek sÄ±nÄ±flarÄ±).\n\n---\n\nâœ… **Ã–zet:**  \nBu aÅŸamada modelin eÄŸitim sÃ¼reci grafiklerle analiz edilmiÅŸ, overfitting/underfitting durumu kontrol edilmiÅŸ ve test seti Ã¼zerinde performansÄ± Ã¶lÃ§Ã¼lmÃ¼ÅŸtÃ¼r. Confusion matrix ve sÄ±nÄ±f bazlÄ± raporlar, modelin hangi sÄ±nÄ±flarda daha baÅŸarÄ±lÄ± olduÄŸunu gÃ¶sterir.\n","metadata":{}},{"cell_type":"code","source":"# 6. Model DeÄŸerlendirme ve Overfitting/Underfitting KontrolÃ¼\nplt.figure(figsize=(12,4))\nplt.subplot(1,2,1)\nplt.plot(history.history['loss'], label='EÄŸitim Loss')\nplt.plot(history.history['val_loss'], label='DoÄŸrulama Loss')\nplt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(history.history['accuracy'], label='EÄŸitim Accuracy')\nplt.plot(history.history['val_accuracy'], label='DoÄŸrulama Accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()\n\n# GerÃ§ekÃ§i overfit/underfit yorumlama\ntrain_acc = history.history['accuracy'][-1]\nval_acc = history.history['val_accuracy'][-1]\n\nacc_diff = abs(val_acc - train_acc)\n\nif acc_diff < 0.06:\n    print(f\"âœ… Model dengeli. EÄŸitim ve doÄŸrulama accuracy farkÄ± Ã§ok kÃ¼Ã§Ã¼k ({acc_diff:.4f}).\")\nelif val_acc < train_acc:\n    print(f\"âš ï¸ Model biraz overfitting yapÄ±yor olabilir. Accuracy farkÄ±: {acc_diff:.4f}\")\nelse:\n    print(f\"âš ï¸ Model biraz underfitting yapÄ±yor olabilir. Accuracy farkÄ±: {acc_diff:.4f}\")\n\ntest_loss, test_acc = final_model.evaluate(X_test, y_test, verbose=0)\nprint(f\"Test Accuracy: {test_acc*100:.2f}%\")\n\ny_pred = np.argmax(final_model.predict(X_test), axis=1)\ny_true = np.argmax(y_test, axis=1)\n\nplt.figure(figsize=(6,4))\nsns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.show()\n\nprint(classification_report(y_true, y_pred, target_names=['Kedi','KÃ¶pek']))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T01:04:11.616756Z","iopub.execute_input":"2025-09-25T01:04:11.617006Z","iopub.status.idle":"2025-09-25T01:04:24.900487Z","shell.execute_reply.started":"2025-09-25T01:04:11.616979Z","shell.execute_reply":"2025-09-25T01:04:24.899919Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Grad-CAM ile GÃ¶rselleÅŸtirme\n\nBu bÃ¶lÃ¼mde, eÄŸitilen CNN modelinin **hangi bÃ¶lgeleri kullanarak sÄ±nÄ±flandÄ±rma yaptÄ±ÄŸÄ±** gÃ¶rselleÅŸtirilir. Bu yÃ¶ntem, modelin karar mekanizmasÄ±nÄ± anlamak ve yorumlamak iÃ§in kullanÄ±lÄ±r.\n\n---\n\n### ğŸ”¹ AmaÃ§\n- Modelin odaklandÄ±ÄŸÄ± alanlarÄ± gÃ¶rselleÅŸtirmek.  \n- SÄ±nÄ±flandÄ±rma kararlarÄ±nÄ±n **gÃ¶rsel olarak aÃ§Ä±klanabilirliÄŸini** artÄ±rmak.  \n- Overfitting veya hatalÄ± sÄ±nÄ±flandÄ±rma durumlarÄ±nÄ± incelemek.\n\n---\n\n### ğŸ”¹ Grad-CAM FonksiyonlarÄ±\n\n1. **make_gradcam_heatmap**  \n   - Son Conv2D katmanÄ± ve model Ã§Ä±ktÄ±sÄ± kullanÄ±larak **gradient tabanlÄ± Ä±sÄ± haritasÄ± (heatmap)** oluÅŸturur.  \n   - `pred_index` belirtilmezse, modelin en yÃ¼ksek tahmine gÃ¶re sÄ±nÄ±f seÃ§ilir.  \n   - Heatmap, ilgili sÄ±nÄ±fa ait Ã¶nem derecelerini 0-1 arasÄ±nda normalize eder.\n\n2. **display_gradcam**  \n   - Heatmapâ€™i orijinal gÃ¶rselin Ã¼zerine uygular.  \n   - `alpha` parametresi ile Ä±sÄ± haritasÄ±nÄ±n opaklÄ±ÄŸÄ± ayarlanÄ±r.  \n   - SonuÃ§, modelin dikkat ettiÄŸi bÃ¶lgelerin gÃ¶rsel olarak anlaÅŸÄ±lmasÄ±nÄ± saÄŸlar.\n\n---\n\n### ğŸ”¹ GÃ¶rselleÅŸtirme AdÄ±mlarÄ±\n- Test setinden rastgele 4 gÃ¶rsel seÃ§ilir.  \n- Her gÃ¶rsel iÃ§in:  \n  - Son Conv2D katmanÄ± belirlenir.  \n  - Grad-CAM Ä±sÄ± haritasÄ± oluÅŸturulur.  \n  - Orijinal gÃ¶rsel ve heatmap birleÅŸtirilerek ekrana Ã§izilir.  \n- BaÅŸlÄ±kta modelin tahmini sÄ±nÄ±f (`Pred`) gÃ¶sterilir.\n\n---\n\nâœ… **Ã–zet:**  \nBu aÅŸamada Grad-CAM yÃ¶ntemi kullanÄ±larak modelin **karar verdiÄŸi bÃ¶lgeler** gÃ¶rselleÅŸtirilmiÅŸ, modelin â€œneden bu sÄ±nÄ±fÄ± seÃ§tiÄŸiâ€ gÃ¶rsel olarak analiz edilmiÅŸtir. BÃ¶ylece modelin aÃ§Ä±klanabilirliÄŸi ve yorumlanabilirliÄŸi artÄ±rÄ±lmÄ±ÅŸtÄ±r.\n","metadata":{}},{"cell_type":"code","source":"# 7. Grad-CAM\nfrom tensorflow.keras.layers import Conv2D\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    grad_model = Model(inputs=model.input,\n                       outputs=[model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(predictions[0])\n        class_channel = predictions[:, pred_index]\n    grads = tape.gradient(class_channel, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = tf.maximum(heatmap,0)/tf.math.reduce_max(heatmap)\n    return heatmap.numpy()\n\ndef display_gradcam(img, heatmap, alpha=0.4):\n    heatmap_resized = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n    heatmap_colored = cv2.applyColorMap(np.uint8(255*heatmap_resized), cv2.COLORMAP_JET)\n    img_original = ((img + 1) * 127.5).astype('uint8')\n    superimposed_img = cv2.addWeighted(img_original, 1-alpha, heatmap_colored, alpha,0)\n    return superimposed_img\n\nplt.figure(figsize=(12,6))\nfor i in range(4):\n    plt.subplot(2,4,i+1)\n    img = np.expand_dims(X_test[i], axis=0)\n    last_conv_layer = [layer.name for layer in final_model.layers if isinstance(layer, Conv2D)][-1]\n    heatmap = make_gradcam_heatmap(img, final_model, last_conv_layer)\n    superimposed = display_gradcam(X_test[i], heatmap)\n    plt.imshow(cv2.cvtColor(superimposed, cv2.COLOR_BGR2RGB))\n    plt.axis('off')\n    plt.title(f'Pred: {y_pred[i]}')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T01:04:24.901202Z","iopub.execute_input":"2025-09-25T01:04:24.901456Z","iopub.status.idle":"2025-09-25T01:04:26.621852Z","shell.execute_reply.started":"2025-09-25T01:04:24.901438Z","shell.execute_reply":"2025-09-25T01:04:26.621205Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Modelin Kaydedilmesi\n\nBu bÃ¶lÃ¼mde, eÄŸitilen model **kalÄ±cÄ± olarak saklanÄ±r** ve ileride tekrar kullanÄ±lmak Ã¼zere hazÄ±r hÃ¢le getirilir.\n\n---\n\n### ğŸ”¹ AmaÃ§\n- Modeli yeniden eÄŸitmeye gerek kalmadan tekrar kullanabilmek.  \n- Test, deployment veya uygulama aÅŸamalarÄ±nda kolaylÄ±k saÄŸlamak.\n\n---\n\n### ğŸ”¹ Ä°ÅŸleyiÅŸ\n- `final_model.save(\"kedi_kopek_model_final.h5\")`  \n  - Modelin aÄŸÄ±rlÄ±klarÄ±, yapÄ±sÄ± ve eÄŸitim bilgileri `.h5` formatÄ±nda kaydedilir.  \n- `print` ile modelin baÅŸarÄ±yla kaydedildiÄŸi kullanÄ±cÄ±ya bildirilir.\n\n---\n\nâœ… **Ã–zet:**  \nBu aÅŸamada, eÄŸitilen CNN modeli `.h5` formatÄ±nda saklanmÄ±ÅŸ ve artÄ±k **kullanÄ±ma hazÄ±r** hÃ¢le gelmiÅŸtir. Model, ileride tekrar yÃ¼klenip test edilebilir veya uygulamalarda kullanÄ±labilir.\n","metadata":{}},{"cell_type":"code","source":"final_model.save(\"kedi_kopek_model_final.h5\")\nprint(\"Model baÅŸarÄ±yla kaydedildi: kedi_kopek_model_final.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-25T01:04:26.622543Z","iopub.execute_input":"2025-09-25T01:04:26.622798Z","iopub.status.idle":"2025-09-25T01:04:26.815204Z","shell.execute_reply.started":"2025-09-25T01:04:26.622776Z","shell.execute_reply":"2025-09-25T01:04:26.814621Z"}},"outputs":[],"execution_count":null}]}